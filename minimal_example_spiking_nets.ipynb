{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook provides a minimal example for using LFP to train a simple MLP-Spiking Neural Network (SNN) on MNIST.\n",
    "\n",
    "For more complex examples, refer to the experiment notebooks in ./nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import snntorch as snn\n",
    "    from snntorch import utils as snnutils\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"The SNN functionality of this package requires extra dependencies \",\n",
    "        \"which can be installed via pip install lfprop[snn] (or lfprop[full] for all dependencies).\",\n",
    "    )\n",
    "    raise ImportError(\"snntorch required; reinstall lfprop with option `snn` (pip install lfprop[snn])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lweber/.cache/pypoetry/virtualenvs/lfprop-KukTaqIE-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torcheval.metrics\n",
    "import torchvision.datasets as tvisiondata\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lfprop.rewards import reward_functions as rewards  # Reward Functions\n",
    "from lfprop.model.models import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./minimal-example-data\"\n",
    "os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "batch_size = 128  # 128\n",
    "n_channels = 784\n",
    "n_outputs = 10\n",
    "n_steps = 15\n",
    "lr = 0.02\n",
    "momentum = 0.9\n",
    "epochs = 3\n",
    "model_name = \"smalllifmlp\"\n",
    "lif_kwargs = {\"beta\": 0.9, \"reset_mechanism\": \"subtract\", \"surrogate_disable\": False, \"spike_grad\": \"step\"}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])\n",
    "training_data = tvisiondata.MNIST(\n",
    "    root=savepath,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "validation_data = tvisiondata.MNIST(\n",
    "    root=savepath,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "# [DEBUG] overfit to a small dataset\n",
    "# training_data = torch.utils.data.Subset(training_data, list(range(0, len(training_data) // 2)))\n",
    "# validation_data = torch.utils.data.Subset(validation_data, list(range(0, 10)) * 100)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallLifMLP(\n",
       "  (classifier): Sequential(\n",
       "    (0): SpikingLayer(\n",
       "      (parameterized_layer): NoisyWrapper(\n",
       "        (module): Linear(in_features=784, out_features=1000, bias=True)\n",
       "      )\n",
       "      (spike_mechanism): Leaky(\n",
       "        (spike_grad): Step()\n",
       "      )\n",
       "    )\n",
       "    (1): SpikingLayer(\n",
       "      (parameterized_layer): NoisyWrapper(\n",
       "        (module): Linear(in_features=1000, out_features=10, bias=True)\n",
       "      )\n",
       "      (spike_mechanism): Leaky(\n",
       "        (spike_grad): Step()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(model_name=model_name, n_channels=n_channels, n_outputs=n_outputs, device=device, **lif_kwargs)\n",
    "model.reset()\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SNN-Propagator\n",
    "from lfprop.propagation.propagator_snn import LFPSNNEpsilonComposite\n",
    "\n",
    "snn_propagator = LFPSNNEpsilonComposite(epsilon=1e-6)\n",
    "\n",
    "# Initialize the Reward Function.\n",
    "reward_func = rewards.SnnCorrectClassRewardSpikesRateCoded(device)\n",
    "\n",
    "# LFP writes its updates into the .grad attribute of the model parameters, and can thus utilize standard torch optimizers\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Simple Evaluation using torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(loader, n_steps: int = 15):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a single dataset\n",
    "    \"\"\"\n",
    "    eval_metrics = {\n",
    "        \"reward\": torcheval.metrics.Mean(device=device),\n",
    "        \"accuracy\": torcheval.metrics.MulticlassAccuracy(average=\"micro\", num_classes=10, k=1, device=device),\n",
    "    }\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()\n",
    "\n",
    "    # Iterate over Data Loader\n",
    "    for index, (inputs, labels) in tqdm(enumerate(loader), desc=\"Evaluating\", total=len(loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = (labels).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Get model predictions\n",
    "            u_rec, spk_rec = [], []\n",
    "            for step in tqdm(range(n_steps), disable=True):  # [ ] move this into the fwd method of the model?\n",
    "                y = model(inputs)\n",
    "                spk_out, u_out = y\n",
    "                u_rec.append(u_out)\n",
    "                spk_rec.append(spk_out)\n",
    "\n",
    "            spikes = torch.stack(spk_rec, dim=0)\n",
    "\n",
    "            # Get rewards\n",
    "            reward = reward_func(spikes=spikes, labels=labels)\n",
    "            outputs = reward_func.get_predictions(spikes=spikes)\n",
    "\n",
    "        for k, v in eval_metrics.items():\n",
    "            if k == \"reward\":\n",
    "                eval_metrics[k].update(reward)\n",
    "            else:\n",
    "                eval_metrics[k].update(outputs, labels)\n",
    "\n",
    "    return_dict = {m: metric.compute().detach().cpu().numpy() for m, metric in eval_metrics.items()}\n",
    "    model.reset()\n",
    "    # Return evaluation\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]/home/lweber/.cache/pypoetry/virtualenvs/lfprop-KukTaqIE-py3.11/lib/python3.11/site-packages/lxt/core.py:362: UserWarning: This functionality is not yet fully tested. Please check the model after removing the composite.\n",
      "  warn(\n",
      "100%|██████████| 469/469 [00:47<00:00,  9.94it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:21<00:00, 22.13it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: (Train Reward) -0.00; (Train Accuracy) 0.88; (Val Reward) -0.00; (Val Accuracy) 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:47<00:00,  9.88it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 21.16it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: (Train Reward) 0.01; (Train Accuracy) 0.92; (Val Reward) 0.01; (Val Accuracy) 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:47<00:00,  9.87it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:21<00:00, 21.60it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: (Train Reward) 0.01; (Train Accuracy) 0.89; (Val Reward) 0.01; (Val Accuracy) 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def lfp_step(inputs, labels, n_steps: int = 15, print_model: bool = False):\n",
    "    \"\"\"\n",
    "    Performs a single training step using LFP. This is quite similar to a standard gradient descent training loop.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.reset()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with snn_propagator.context(model) as modified:\n",
    "        inputs = inputs.detach().requires_grad_(True)\n",
    "        \n",
    "        if print_model:\n",
    "            print(modified)\n",
    "        \n",
    "        # Forward pass\n",
    "        u_rec, spk_rec = [], []\n",
    "        for step in range(n_steps):\n",
    "            outputs = modified(inputs)\n",
    "            spk_out, u_out = outputs\n",
    "            u_rec.append(u_out)\n",
    "            spk_rec.append(spk_out)\n",
    "        spikes = torch.stack(spk_rec, dim=0)\n",
    "        membrane_potential = torch.stack(u_rec, dim=0)\n",
    "\n",
    "        # Reward\n",
    "        reward = torch.from_numpy(reward_func(spikes=spikes, labels=labels).detach().cpu().numpy()).to(device)\n",
    "        reward /= n_steps\n",
    "\n",
    "        # Backward pass\n",
    "        torch.autograd.grad((spikes,), (inputs,), grad_outputs=(reward,), retain_graph=False)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if not hasattr(param, 'feedback'):\n",
    "            print(f\"Parameter {name} does not have feedback attribute.\")\n",
    "        param.grad = -param.feedback\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 3.0, 2.0)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(total=len(training_loader)) as pbar:\n",
    "        # Iterate over Data Loader\n",
    "        for index, (inputs, labels) in enumerate(training_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Perform Update Step\n",
    "            lfp_step(inputs, labels, n_steps=n_steps)\n",
    "\n",
    "            # Update Progress Bar\n",
    "            pbar.update(1)\n",
    "            # if index >= 30:\n",
    "            # break\n",
    "\n",
    "    # Evaluate and print performance after every epoch\n",
    "    eval_stats_train = eval_model(training_loader, n_steps=n_steps)\n",
    "    eval_stats_val = eval_model(validation_loader, n_steps=n_steps)\n",
    "    print(\n",
    "        \"Epoch {}/{}: (Train Reward) {:.2f}; (Train Accuracy) {:.2f}; (Val Reward) {:.2f}; (Val Accuracy) {:.2f}\".format(\n",
    "            epoch + 1,\n",
    "            epochs,\n",
    "            float(np.mean(eval_stats_train[\"reward\"])),\n",
    "            float(eval_stats_train[\"accuracy\"]),\n",
    "            float(np.mean(eval_stats_val[\"reward\"])),\n",
    "            float(eval_stats_val[\"accuracy\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# training takes approx. 5 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfprop-KukTaqIE-py3.11 (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
