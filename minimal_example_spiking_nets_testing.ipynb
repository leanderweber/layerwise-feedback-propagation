{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook provides a minimal example for using LFP to train a simple MLP-Spiking Neural Network (SNN) on MNIST.\n",
    "\n",
    "For more complex examples, refer to the experiment notebooks in ./nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import snntorch as snn\n",
    "    from snntorch import utils as snnutils\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"The SNN functionality of this package requires extra dependencies \",\n",
    "        \"which can be installed via pip install lfprop[snn] (or lfprop[full] for all dependencies).\",\n",
    "    )\n",
    "    raise ImportError(\"snntorch required; reinstall lfprop with option `snn` (pip install lfprop[snn])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torcheval.metrics\n",
    "import torchvision.datasets as tvisiondata\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lfprop.rewards import reward_functions as rewards  # Reward Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./minimal-example-data\"\n",
    "os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "batch_size = 128  # 128\n",
    "n_channels = 1 #784\n",
    "n_outputs = 10\n",
    "n_steps = 15\n",
    "lr = 0.02\n",
    "momentum = 0.9\n",
    "epochs = 20\n",
    "model_name = \"lifcnn\"\n",
    "lif_kwargs = {\"beta\": 0.9, \"reset_mechanism\": \"subtract\"}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])\n",
    "training_data = tvisiondata.MNIST(\n",
    "    root=savepath,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "validation_data = tvisiondata.MNIST(\n",
    "    root=savepath,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "# [DEBUG] overfit to a small dataset\n",
    "# training_data = torch.utils.data.Subset(training_data, list(range(0, len(training_data) // 2)))\n",
    "# validation_data = torch.utils.data.Subset(validation_data, list(range(0, 10)) * 100)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfprop.model.spiking_networks import get_model\n",
    "\n",
    "model = get_model(model_name=model_name, n_channels=n_channels, n_outputs=n_outputs, device=device, **lif_kwargs)\n",
    "model.reset()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def name_modules(module, name):\n",
    "    \"\"\"\n",
    "    Recursive function to name modules for debugging \n",
    "    \"\"\"\n",
    "    \n",
    "    for cname, child in module.named_children():\n",
    "        child.tmpname = cname if name == \"root\" else f\"{name}.{cname}\"\n",
    "        name_modules(child, child.tmpname)\n",
    "\n",
    "name_modules(model, \"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lweber/.cache/pypoetry/virtualenvs/lfprop-KukTaqIE-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SNN-Propagator\n",
    "from lfprop.propagation.propagator_snn import LFPSNNEpsilonComposite\n",
    "\n",
    "propagation_composite = LFPSNNEpsilonComposite(epsilon=1e-6)\n",
    "\n",
    "# Initialize the Reward Function.\n",
    "reward_func = rewards.SnnCorrectClassRewardSpikesRateCoded(device)\n",
    "\n",
    "# LFP writes its updates into the .grad attribute of the model parameters, and can thus utilize standard torch optimizers\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Simple Evaluation using torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(loader, n_steps: int = 15):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a single dataset\n",
    "    \"\"\"\n",
    "    eval_metrics = {\n",
    "        \"reward\": torcheval.metrics.Mean(device=device),\n",
    "        \"accuracy\": torcheval.metrics.MulticlassAccuracy(average=\"micro\", num_classes=10, k=1, device=device),\n",
    "    }\n",
    "\n",
    "    model.eval()\n",
    "    model.reset()\n",
    "\n",
    "    # Iterate over Data Loader\n",
    "    for index, (inputs, labels) in tqdm(enumerate(loader), desc=\"Evaluating\", total=len(loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = (labels).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Get model predictions\n",
    "            u_rec, spk_rec = [], []\n",
    "            for step in tqdm(range(n_steps), disable=True):  # [ ] move this into the fwd method of the model?\n",
    "                y = model(inputs)\n",
    "                spk_out, u_out = y\n",
    "                u_rec.append(u_out)\n",
    "                spk_rec.append(spk_out)\n",
    "\n",
    "            spikes = torch.stack(spk_rec, dim=0)\n",
    "            membrane_potential = torch.stack(u_rec, dim=0)\n",
    "\n",
    "            # Get rewards\n",
    "            reward = reward_func(spikes=spikes, potentials=membrane_potential, labels=labels)\n",
    "            outputs = reward_func.get_predictions(spikes=spikes, potentials=membrane_potential)\n",
    "\n",
    "        for k, v in eval_metrics.items():\n",
    "            if k == \"reward\":\n",
    "                eval_metrics[k].update(reward)\n",
    "            else:\n",
    "                eval_metrics[k].update(outputs, labels)\n",
    "\n",
    "    return_dict = {m: metric.compute().detach().cpu().numpy() for m, metric in eval_metrics.items()}\n",
    "    model.reset()\n",
    "    # Return evaluation\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]/home/lweber/.cache/pypoetry/virtualenvs/lfprop-KukTaqIE-py3.11/lib/python3.11/site-packages/lxt/core.py:362: UserWarning: This functionality is not yet fully tested. Please check the model after removing the composite.\n",
      "  warn(\n",
      "100%|██████████| 469/469 [01:03<00:00,  7.40it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: (Train Reward) 0.01; (Train Accuracy) 0.80; (Val Reward) 0.01; (Val Accuracy) 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:58<00:00,  8.06it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: (Train Reward) 0.02; (Train Accuracy) 0.76; (Val Reward) 0.02; (Val Accuracy) 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:58<00:00,  8.08it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 19.95it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: (Train Reward) 0.01; (Train Accuracy) 0.66; (Val Reward) 0.01; (Val Accuracy) 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:58<00:00,  7.95it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.10it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: (Train Reward) 0.04; (Train Accuracy) 0.66; (Val Reward) 0.03; (Val Accuracy) 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:55<00:00,  8.39it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.26it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: (Train Reward) 0.04; (Train Accuracy) 0.64; (Val Reward) 0.04; (Val Accuracy) 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:55<00:00,  8.47it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.24it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: (Train Reward) 0.04; (Train Accuracy) 0.64; (Val Reward) 0.04; (Val Accuracy) 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:58<00:00,  8.02it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.53it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: (Train Reward) 0.04; (Train Accuracy) 0.59; (Val Reward) 0.03; (Val Accuracy) 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:56<00:00,  8.36it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.37it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: (Train Reward) 0.04; (Train Accuracy) 0.57; (Val Reward) 0.04; (Val Accuracy) 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:55<00:00,  8.41it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.81it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: (Train Reward) 0.03; (Train Accuracy) 0.58; (Val Reward) 0.03; (Val Accuracy) 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:57<00:00,  8.14it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.76it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: (Train Reward) 0.04; (Train Accuracy) 0.57; (Val Reward) 0.04; (Val Accuracy) 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:55<00:00,  8.48it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.68it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: (Train Reward) 0.03; (Train Accuracy) 0.55; (Val Reward) 0.03; (Val Accuracy) 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:55<00:00,  8.39it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.19it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: (Train Reward) 0.04; (Train Accuracy) 0.54; (Val Reward) 0.04; (Val Accuracy) 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:56<00:00,  8.29it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.30it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: (Train Reward) 0.04; (Train Accuracy) 0.52; (Val Reward) 0.04; (Val Accuracy) 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:57<00:00,  8.10it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.68it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: (Train Reward) 0.05; (Train Accuracy) 0.53; (Val Reward) 0.05; (Val Accuracy) 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:55<00:00,  8.44it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:22<00:00, 20.79it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: (Train Reward) 0.04; (Train Accuracy) 0.51; (Val Reward) 0.04; (Val Accuracy) 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:57<00:00,  8.18it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.11it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: (Train Reward) 0.04; (Train Accuracy) 0.50; (Val Reward) 0.04; (Val Accuracy) 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:56<00:00,  8.32it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.29it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: (Train Reward) 0.04; (Train Accuracy) 0.50; (Val Reward) 0.03; (Val Accuracy) 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:57<00:00,  8.14it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.25it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: (Train Reward) 0.03; (Train Accuracy) 0.48; (Val Reward) 0.03; (Val Accuracy) 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:58<00:00,  7.99it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.11it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: (Train Reward) 0.05; (Train Accuracy) 0.49; (Val Reward) 0.05; (Val Accuracy) 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:56<00:00,  8.36it/s]\n",
      "Evaluating: 100%|██████████| 469/469 [00:23<00:00, 20.23it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:03<00:00, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: (Train Reward) 0.05; (Train Accuracy) 0.48; (Val Reward) 0.04; (Val Accuracy) 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def lfp_step(inputs, labels, n_steps: int = 15):\n",
    "    \"\"\"\n",
    "    Performs a single training step using LFP. This is quite similar to a standard gradient descent training loop.\n",
    "    \"\"\"\n",
    "    # Set Model to training mode\n",
    "    model.train()\n",
    "    model.reset()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # Zero Optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with propagation_composite.context(model) as modified:\n",
    "    \n",
    "            inputs = inputs.detach().requires_grad_(True)\n",
    "        \n",
    "            # Model forward pass\n",
    "            u_rec, spk_rec = [], []\n",
    "            for step in tqdm(range(n_steps), disable=True):\n",
    "                outputs = modified(inputs)\n",
    "                spk_out, u_out = outputs\n",
    "                u_rec.append(u_out)\n",
    "                spk_rec.append(spk_out)\n",
    "            spikes = torch.stack(spk_rec, dim=0)\n",
    "            membrane_potential = torch.stack(u_rec, dim=0)\n",
    "\n",
    "            # Reward\n",
    "            reward = torch.from_numpy(reward_func(spikes=spikes, potentials=membrane_potential, labels=labels).detach().cpu().numpy()).to(device)\n",
    "            reward /= n_steps #Total reward should not increase with additional steps\n",
    "\n",
    "            #print(reward.sum())\n",
    "\n",
    "            # Modified Backward Pass\n",
    "            #for step in range(n_steps):\n",
    "            #    torch.autograd.grad((spk_rec[n_steps-(step+1)],), (inputs,), grad_outputs=(reward[n_steps-(step+1)],), retain_graph=False)\n",
    "            torch.autograd.grad((spikes,), (inputs,), grad_outputs=(reward,), retain_graph=False)\n",
    "            #snn_propagator.propagate(iteration_feedback=reward[-(step + 1)], iteration_idx=step)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        param.grad = -param.feedback\n",
    "        #print(name, param.feedback.abs().sum(), param.data.abs().sum())\n",
    "\n",
    "    # Update Clipping. Training may become unstable otherwise, especially in small models with large learning rates.\n",
    "    # In larger models (e.g., VGG, ResNet), where smaller learning rates are generally utilized, not clipping updates may result in better performance.\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 3.0, 2.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Set Model back to eval model\n",
    "    model.reset()  # necessary to free the internal state of the model\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(total=len(training_loader)) as pbar:\n",
    "        # Iterate over Data Loader\n",
    "        for index, (inputs, labels) in enumerate(training_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = (labels).to(device)\n",
    "\n",
    "            # Perform Update Step\n",
    "            lfp_step(inputs, labels, n_steps=n_steps)\n",
    "\n",
    "            # Update Progress Bar\n",
    "            pbar.update(1)\n",
    "            # if index >= 30:\n",
    "            # break\n",
    "\n",
    "    # Evaluate and print performance after every epoch\n",
    "    eval_stats_train = eval_model(training_loader, n_steps=n_steps)\n",
    "    eval_stats_val = eval_model(validation_loader, n_steps=n_steps)\n",
    "    print(\n",
    "        \"Epoch {}/{}: (Train Reward) {:.2f}; (Train Accuracy) {:.2f}; (Val Reward) {:.2f}; (Val Accuracy) {:.2f}\".format(\n",
    "            epoch + 1,\n",
    "            epochs,\n",
    "            float(np.mean(eval_stats_train[\"reward\"])),\n",
    "            float(eval_stats_train[\"accuracy\"]),\n",
    "            float(np.mean(eval_stats_val[\"reward\"])),\n",
    "            float(eval_stats_val[\"accuracy\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# training takes approx. 5 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfprop-KukTaqIE-py3.11 (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
